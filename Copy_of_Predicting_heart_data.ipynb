{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OA21796/L3T1/blob/ope/Copy_of_Predicting_heart_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "wjL3sIgQhCOP",
        "outputId": "267745f8-9f26-46bf-8dcb-921bbcd847ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b67a81e3-531b-4290-a73f-f22b7b525282\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b67a81e3-531b-4290-a73f-f22b7b525282\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving heart.csv to heart (1).csv\n",
            "Best Parameters for SVC: {'C': 100, 'gamma': 'auto', 'kernel': 'poly'}\n",
            "\n",
            "SVM with GridSearchCV Accuracy: 0.8841\n",
            "Classification Report for SVM with GridSearchCV:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.84      0.90      0.87        30\n",
            "           1       0.92      0.87      0.89        39\n",
            "\n",
            "    accuracy                           0.88        69\n",
            "   macro avg       0.88      0.89      0.88        69\n",
            "weighted avg       0.89      0.88      0.88        69\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Importing the relevant libraries required for use to display and query dataset\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# import used to plot graphs & charts etc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "import plotly.graph_objs as go\n",
        "import plotly.offline as py\n",
        "\n",
        "#Import required to be able to import a file from users desktop\n",
        "from google.colab import files\n",
        "\n",
        "#For machine learning\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "\n",
        "\n",
        "#Source: https://www.kaggle.com/code/microvision/heart-disease-exploratory-data-analysis/notebook\n",
        "# [2]\n",
        "def readData():\n",
        "  \"\"\" reads and returns the csv \"\"\"\n",
        "  heart_data = pd.read_csv(\"heart.csv\")\n",
        "  return heart_data\n",
        "\n",
        "\n",
        "\n",
        "# [3] & [5]\n",
        "def printHead(heart_data):\n",
        "  \"\"\" Previews the dataset \"\"\"\n",
        "  print(heart_data.head())\n",
        "\n",
        "\n",
        "\n",
        "# [4]\n",
        "def renameColumns(heart_data):\n",
        "  \"\"\" Renames the columns to a better understood column name \"\"\"\n",
        "  heart_data.columns = ['Age', 'Sex', 'Chest_pain_type', 'Resting_bp',\n",
        "              'Cholesterol', 'Fasting_bs', 'Resting_ecg',\n",
        "              'Max_heart_rate', 'Exercise_induced_angina',\n",
        "              'ST_depression', 'ST_slope', 'Num_major_vessels',\n",
        "              'Thallium_test', 'Condition',\n",
        "              ]\n",
        "  return heart_data\n",
        "\n",
        "\n",
        "\n",
        "# [6]\n",
        "def describeData(heart_data):\n",
        "  \"\"\" DescribeData takes in the csv, and prints a summary of the following:\n",
        "     -> count             -> min\n",
        "     -> mean              -> 25% percentile\n",
        "     -> std               -> 50% percintile\n",
        "     -> 75% percintile    -> max val \"\"\"\n",
        "\n",
        "  print(heart_data.describe())\n",
        "\n",
        "\n",
        "\n",
        "# [7]\n",
        "def infoData(heart_data):\n",
        "  \"\"\" This prints the data types, memory usage, no. of features, and no. of entries made \"\"\"\n",
        "  heart_data.info() # prints numbered row by row with datatype, and non null count.\n",
        "  print()\n",
        "  print(f'Shape of the dataset')\n",
        "  print(f'Number of Features: {heart_data.shape[1]}')\n",
        "  print(f'Number of Observations: {heart_data.shape[0]}')\n",
        "  # the print statements return the numb of columns and no of entries. f\" formatted\n",
        "\n",
        "\n",
        "\n",
        "# [8]\n",
        "def checkMissingValues(heart_data):\n",
        "  \"\"\" This checks for missing values in any row \"\"\"\n",
        "  print(\"{:<8}\\033[1m Missing values\".format(\" \"))\n",
        "  print(heart_data.isnull().sum())\n",
        "  # At current there are no missing values in the dataset\n",
        "\n",
        "\n",
        "\n",
        "# [9]\n",
        "def conditionPieChart(data):\n",
        "    \"\"\"\n",
        "    Make a pie chart of 'Condition' values\n",
        "    Condition: 0 = Benign, 1 = Malignant\n",
        "    0 means they do NOT have heart disease. 1 is opposite.\n",
        "    \"\"\"\n",
        "    results = data['Condition'].value_counts()\n",
        "    values = [results[0], results[1]]\n",
        "    labels = ['Benign', 'Malignant']\n",
        "    colors = ['lime', 'red']\n",
        "\n",
        "    fig_pie = go.Pie(labels=labels, values=values,\n",
        "                     marker={'colors': colors,\n",
        "                             'line': {'color': 'Black', 'width': 2}})\n",
        "    py.iplot([fig_pie])\n",
        "    print(py)\n",
        "    print(\"\\nObservations: Most members in the dataset are diagnosed with Malignant, 54.5% (165 cases).\"\n",
        "    \"On the other hand, the proportion of Benign in Condition is less than 50%.\")\n",
        "\n",
        "\n",
        "\n",
        "# [10]\n",
        "def sex_ratio(data):\n",
        "  \"\"\"\n",
        "  Make a pie chart of 'Sex' values\n",
        "  Sex: 0 = Female, 1 = Male\n",
        "  A pie chart displaying the ratio between men and women\n",
        "  \"\"\"\n",
        "  print(\"{:<55}\\033[1m Pie Chart showing ratio between Men:Women\".format(\" \"))\n",
        "  # Pie chart of sex ratio\n",
        "  results = data['Sex'].value_counts()\n",
        "  values = [results[0], results[1]]\n",
        "  labels = ['Female', 'Male']\n",
        "  colors = ['Red', 'RoyalBlue']\n",
        "\n",
        "  fig_pie = go.Pie(labels=labels, values=values,\n",
        "                    marker={'colors': colors,\n",
        "                            'line': {'color': 'Black', 'width': 2}})\n",
        "  py.iplot([fig_pie])\n",
        "  print(py)\n",
        "  print(\"\\nObservations: Most members in the dataset are male, 68.7% male compared to 31.3% female\")\n",
        "\n",
        "\n",
        "\n",
        "# [11]\n",
        "def conditionPerSex(data):\n",
        "    \"\"\"\n",
        "    Plot a bar chart of the proportion of Conditon vs.  Sex.\n",
        "    Show the percentage of Malignant for each sex.\n",
        "    \"\"\"\n",
        "    # Bivariate analysis: Sex vs. Condition\n",
        "    data['Sex'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Sex', y='proportion', hue='Condition', palette='Dark2');\n",
        "    plt.title('Proportion of Condition for Sex')\n",
        "    plt.xlabel('Sex (0 = Female, 1 = Male)')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    # Show the percentage of Malignant for Sex\n",
        "    # female_malignant vs. Malignant\n",
        "    female_malignant = data[data['Sex']==0]['Condition'].sum()/data[data['Condition']==1]['Condition'].count()\n",
        "    # male_malignant vs. Malignant\n",
        "    male_malignant = data[data['Sex']==1]['Condition'].sum()/data[data['Condition']==1]['Condition'].count()\n",
        "\n",
        "    print('The proportion of Malignant for Sex:')\n",
        "    print(f'Female: {female_malignant:.2%}')\n",
        "    print(f'Male: {male_malignant:.2%}')\n",
        "    # I may only need the percentages and not the bar chart??\n",
        "\n",
        "\n",
        "\n",
        "# [12]\n",
        "def risk_factors_fbs(data):\n",
        "    \"\"\"\n",
        "    Plot bar charts of fasting blood sugar (over 120 mg/dl) and compare for Sex and Condition\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(20, 6))\n",
        "\n",
        "    # Fasting blood sugar > 120 mg/dl\n",
        "    plt.subplot(1, 3, 1)\n",
        "    sns.countplot(x='Fasting_bs', data=data)\n",
        "    plt.title('Fasting blood sugar (over 120 mg/dl)')\n",
        "    plt.xlabel('Fasting_bs (0 = False, 1 = True)')\n",
        "\n",
        "\n",
        "    # Fasting blood sugar for Sex\n",
        "    plt.subplot(1, 3, 2)\n",
        "    data['Fasting_bs'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Fasting_bs', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of Fasting_bs (over 120 mg/dl) for Sex')\n",
        "    plt.xlabel('Fasting_bs (0 = False, 1 = True)')\n",
        "\n",
        "\n",
        "    # Fasting blood sugar for Condition\n",
        "    plt.subplot(1, 3, 3)\n",
        "    data['Fasting_bs'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Fasting_bs', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Proportion of Fasting_bs (over 120 mg/dl) for Condition')\n",
        "    plt.xlabel('Fasting_bs (0 = False, 1 = True)')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [13]\n",
        "def risk_factors_dist(data):\n",
        "    \"\"\"\n",
        "    Show distributions of risk factors, Resting_bp, Chlesterol, and Max_heart_rate\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "    # Resting blood pressure\n",
        "    plt.subplot(2, 3, 1)\n",
        "    sns.distplot(data['Resting_bp'])\n",
        "    plt.title('Resting Blood Pressure (mmHg) Distribution', fontsize=15)\n",
        "    plt.axvline(x=130, color='r', linestyle='--', label='Hypertension: over 130 mmHg')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.boxplot(data['Resting_bp'], orient='h')\n",
        "\n",
        "\n",
        "    # Serum cholesterol\n",
        "    plt.subplot(2, 3, 2)\n",
        "    sns.distplot(data['Cholesterol'])\n",
        "    plt.title('Serum Cholesterol (mg/dl) Distribution', fontsize=15)\n",
        "    plt.axvline(x=200, color='r', linestyle='--', label='High Cholesterol: over 200 mg/dl')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.boxplot(data['Cholesterol'], orient='h')\n",
        "\n",
        "\n",
        "    # Maximum heart rate\n",
        "    plt.subplot(2, 3, 3)\n",
        "    sns.distplot(data['Max_heart_rate'])\n",
        "    plt.title('Max Heart Rate Achieved (bpm) Distribution', fontsize=15)\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.boxplot(data['Max_heart_rate'], orient='h')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [14]\n",
        "def riskFactors_bySex(data):\n",
        "    \"\"\"\n",
        "    Show distributions of risk factors for each sex\n",
        "    Risk factors include:\n",
        "     -> Resting blood pressure\n",
        "     -> Chloestrerol level\n",
        "     -> Max heart rate\n",
        "    All presented with a distribution table and standard deviation graph***\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "    # Resting blood pressure for each sex\n",
        "    plt.subplot(2, 3, 1)\n",
        "    trestbps_female = data[data['Sex']==0]['Resting_bp']\n",
        "    trestbps_male = data[data['Sex']==1]['Resting_bp']\n",
        "    sns.histplot(trestbps_female, color='Red')\n",
        "    sns.histplot(trestbps_male, color='Blue')\n",
        "    plt.title('Resting Blood Pressure (mmHg) Distribution for Each Sex')\n",
        "    plt.gca().legend(title='Sex', labels=['Female','Male'])\n",
        "    plt.axvline(x=130, color='r', linestyle='--', label='Hypertension: over 130 mmHg')\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.boxplot(x=data['Resting_bp'], y=data['Sex'],\n",
        "                palette='Set1', orient='h')\n",
        "\n",
        "\n",
        "    # Serum cholesterol distribution for each sex\n",
        "    plt.subplot(2, 3, 2)\n",
        "    chol_female = data[data['Sex']==0]['Cholesterol']\n",
        "    chol_male = data[data['Sex']==1]['Cholesterol']\n",
        "    sns.histplot(chol_female, color='Red')\n",
        "    sns.histplot(chol_male, color='Blue')\n",
        "    plt.title('Serum Cholesterol (mg/dl) Distribution for Each Sex')\n",
        "    plt.gca().legend(title='Sex', labels=['Female','Male'])\n",
        "    plt.axvline(x=200, color='r', linestyle='--', label='High Cholesterol: over 200 mg/dl')\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.boxplot(x=data['Cholesterol'], y=data['Sex'],\n",
        "                palette='Set1', orient='h')\n",
        "\n",
        "\n",
        "    # Max heart rate distribution for each sex\n",
        "    plt.subplot(2, 3, 3)\n",
        "    thalach_female = data[data['Sex']==0]['Max_heart_rate']\n",
        "    thalach_male = data[data['Sex']==1]['Max_heart_rate']\n",
        "    sns.histplot(thalach_female, color='Red')\n",
        "    sns.histplot(thalach_male, color='Blue')\n",
        "    plt.title('Max Heart Rate (bpm) Distribution for Each Sex')\n",
        "    plt.gca().legend(title='Sex', labels=['Female','Male'])\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.boxplot(x=data['Max_heart_rate'], y=data['Sex'],\n",
        "                palette='Set1', orient='h')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [15]\n",
        "def risk_factors_dist_condition(data):\n",
        "    \"\"\"\n",
        "    Show distributions of risk factors for each condition\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "    # Resting blood pressure distribution for each condition\n",
        "    plt.subplot(2, 3, 1)\n",
        "    trestbps_b = data[data['Condition']==0]['Resting_bp']\n",
        "    trestbps_m = data[data['Condition']==1]['Resting_bp']\n",
        "    sns.histplot(trestbps_b, color='Green', kde = True)\n",
        "    sns.histplot(trestbps_m, color='Red', kde = True)\n",
        "    plt.title('Resting Blood Pressure (mmHg) Distribution for Condition')\n",
        "    plt.gca().legend(title='Condition', labels=['Benign','Malignant'])\n",
        "    plt.axvline(x=130, color='r', linestyle='--', label='Hypertension: over 130 mmHg')\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.boxplot(x=data['Resting_bp'], y=data['Condition'],\n",
        "                orient='h', palette='Dark2')\n",
        "\n",
        "\n",
        "    # Serum cholesterol distribution for each condition\n",
        "    plt.subplot(2, 3, 2)\n",
        "    chol_b = data[data['Condition']==0]['Cholesterol']\n",
        "    chol_m = data[data['Condition']==1]['Cholesterol']\n",
        "    sns.histplot(chol_b, color='Green', kde = True)\n",
        "    sns.histplot(chol_m, color='Red', kde = True)\n",
        "    plt.title('Serum Cholesterol (mg/dl) Distribution for Condition')\n",
        "    plt.gca().legend(title='Condition', labels=['Benign','Malignant'])\n",
        "    plt.axvline(x=200, color='r', linestyle='--', label='High Cholesterol: over 200 mg/dl')\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.boxplot(x=data['Cholesterol'], y=data['Condition'],\n",
        "                orient='h', palette='Dark2')\n",
        "\n",
        "\n",
        "    # Max heart rate achieved distribution for each condition\n",
        "    plt.subplot(2, 3, 3)\n",
        "    thalach_b = data[data['Condition']==0]['Max_heart_rate']\n",
        "    thalach_m = data[data['Condition']==1]['Max_heart_rate']\n",
        "    sns.histplot(thalach_b, color='Green', kde = True)\n",
        "    sns.histplot(thalach_m, color='Red', kde = True)\n",
        "    plt.title('Max Heart Rate (bpm) Distribution for Condition')\n",
        "    plt.gca().legend(title='Condition', labels=['Benign','Malignant'])\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.boxplot(x=data['Max_heart_rate'], y=data['Condition'],\n",
        "                orient='h', palette='Dark2')\n",
        "\n",
        "\n",
        "\n",
        "# [16]\n",
        "def symptoms_features(data):\n",
        "    \"\"\"\n",
        "    Count the number of Chest_pain_type and Exercise_induced_angina values.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Chest pain types\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.countplot(x='Chest_pain_type', data=data)\n",
        "    plt.title('Chest Pain Types')\n",
        "\n",
        "\n",
        "    # Exercise induced angina\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.countplot(x='Exercise_induced_angina', data=data)\n",
        "    plt.title('Exercise Induced Angina')\n",
        "\n",
        "\n",
        "\n",
        "# [17]\n",
        "def symptoms_features_sex(data):\n",
        "    \"\"\"\n",
        "    Plot bar charts of chest pain type and exercise induced angina for Sex.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Chest pain types for Sex\n",
        "    plt.subplot(1, 2, 1)\n",
        "    data['Chest_pain_type'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Chest_pain_type', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of Chest pain types for Sex')\n",
        "\n",
        "\n",
        "    # Exercise induced angina for Sex\n",
        "    plt.subplot(1, 2, 2)\n",
        "    data['Exercise_induced_angina'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Exercise_induced_angina', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of Exercise induced angina for Sex')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [18]\n",
        "def symptoms_features_condition(data):\n",
        "    \"\"\"\n",
        "    Plot bar charts of chest pain type and exercise induced angina for Condition.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    data['Chest_pain_type'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Chest_pain_type', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Proportion of Chest pain types for Condition')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    data['Exercise_induced_angina'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Exercise_induced_angina', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Proportion of Exercise induced angina for Condition')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [19]\n",
        "def heart_functions(data):\n",
        "    \"\"\"\n",
        "    Make a bar chart of Resting_ecg and ST_slope.\n",
        "\n",
        "    Parameters:\n",
        "    - data: DataFrame containing the heart data with columns 'Resting_ecg' and 'ST_slope'.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Resting_ecg\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.countplot(x='Resting_ecg', data=data)\n",
        "    plt.title('Resting electrocardiographic results')\n",
        "\n",
        "    # ST_slope\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.countplot(x='ST_slope', data=data)\n",
        "    plt.title('The slope of the peak exercise ST segment')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [20]\n",
        "def heart_functions_sex(data):\n",
        "    \"\"\"\n",
        "    Plot the proportion of Resting_ecg and ST_slope for Sex.\n",
        "\n",
        "    Parameters:\n",
        "    - data: DataFrame containing the heart data with columns 'Resting_ecg', 'ST_slope', and 'Sex'.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Resting_ecg\n",
        "    plt.subplot(1, 2, 1)\n",
        "    data['Resting_ecg'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Resting_ecg', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of Resting electrocardiographic results for Sex')\n",
        "\n",
        "    # ST_slope\n",
        "    plt.subplot(1, 2, 2)\n",
        "    data['ST_slope'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='ST_slope', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of the slope of the peak exercise ST segment for Sex')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [21]\n",
        "def plot_condition_features(data):\n",
        "    \"\"\"\n",
        "    Plot the proportion of Resting_ecg and ST_slope for different heart conditions.\n",
        "\n",
        "    Parameters:\n",
        "    - data: DataFrame containing the heart data with columns 'Resting_ecg', 'ST_slope', and 'Condition'.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Resting_ecg\n",
        "    plt.subplot(1, 2, 1)\n",
        "    data['Resting_ecg'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Resting_ecg', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Proportion of Resting electrocardiographic results for Condition')\n",
        "\n",
        "\n",
        "    # ST_slope\n",
        "    plt.subplot(1, 2, 2)\n",
        "    data['ST_slope'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='ST_slope', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Proportion of the slope of the peak exercise ST segment for Condition')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [22]\n",
        "def explore_sex_related_variables(data):\n",
        "    \"\"\"\n",
        "    Visualize the distribution of ST-depression induced by exercise relative to rest,\n",
        "    segmented by sex and heart disease condition.\n",
        "\n",
        "    Parameters:\n",
        "    - data: A pandas DataFrame containing heart disease data.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 8))\n",
        "\n",
        "    # ST-depression induced by exercise relative to rest\n",
        "    plt.subplot(2, 3, 1)\n",
        "    sns.distplot(data['ST_depression'])\n",
        "    plt.title('ST-depression induced by exercise relative to rest', fontsize=15)\n",
        "    plt.axvline(x=0.5, color='r', linestyle='--', label='Normal')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.boxplot(data['ST_depression'], orient='h')\n",
        "\n",
        "\n",
        "    # ST-depression for Sex\n",
        "    plt.subplot(2, 3, 2)\n",
        "    chol_female = data[data['Sex']==0]['ST_depression']\n",
        "    chol_male = data[data['Sex']==1]['ST_depression']\n",
        "    sns.distplot(chol_female, color='Red')\n",
        "    sns.distplot(chol_male, color='Blue')\n",
        "    plt.title('ST-depression Distribution for Sex')\n",
        "    plt.gca().legend(title='Sex', labels=['Female','Male'])\n",
        "    plt.axvline(x=0.5, color='r', linestyle='--', label='Normal')\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.boxplot(x=data['ST_depression'], y=data['Sex'],\n",
        "                palette='Set1', orient='h')\n",
        "\n",
        "\n",
        "    # ST-depression for Condition\n",
        "    plt.subplot(2, 3, 3)\n",
        "    thalach_b = data[data['Condition']==0]['ST_depression']\n",
        "    thalach_m = data[data['Condition']==1]['ST_depression']\n",
        "    sns.distplot(thalach_b, color='Green')\n",
        "    sns.distplot(thalach_m, color='Red')\n",
        "    plt.title('ST-depression Distribution for Condition')\n",
        "    plt.gca().legend(title='Condition', labels=['Benign','Malignant'])\n",
        "    plt.axvline(x=0.5, color='r', linestyle='--', label='Normal')\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.boxplot(x=data['ST_depression'], y=data['Condition'],\n",
        "                palette='Dark2', orient='h')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [23]\n",
        "def explore_numeric_variables(data):\n",
        "    \"\"\"\n",
        "    Visualize the distribution of numeric variables related to heart disease.\n",
        "\n",
        "    This function generates visualizations to explore the distribution of numeric\n",
        "    variables such as the number of major vessels colored by flourosopy and the\n",
        "    results of Thallium scintigraphy in the provided heart disease dataset.\n",
        "\n",
        "    Parameters:\n",
        "    - data: A pandas DataFrame containing heart disease data.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Num_major_vessels\n",
        "    plt.subplot(1, 2, 1)\n",
        "    sns.countplot(x='Num_major_vessels', data=data)\n",
        "    plt.title('Number of major vessels colored by flourosopy')\n",
        "\n",
        "    # Thallium\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.countplot(x='Thallium_test', data=data)\n",
        "    plt.title('Thallium scintigraphy')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [24]\n",
        "def plot_heart_sex_proportions(data):\n",
        "    \"\"\"\n",
        "    Plot proportions of Num_major_vessels and Thallium_test for Sex.\n",
        "\n",
        "    Parameters:\n",
        "    - data: pandas DataFrame containing heart disease data.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Num_major_vessels\n",
        "    plt.subplot(1, 2, 1)\n",
        "    data['Num_major_vessels'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Num_major_vessels', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of Number of major vessels colored by flourosopy for Sex')\n",
        "\n",
        "    # Thallium test\n",
        "    plt.subplot(1, 2, 2)\n",
        "    data['Thallium_test'].groupby(data['Sex']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Thallium_test', y='proportion', hue='Sex', palette='Set1')\n",
        "    plt.title('Proportion of Thallium scintigraphy for Sex')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [25]\n",
        "def plot_heart_condition_proportions(data):\n",
        "    \"\"\"\n",
        "    Plot proportions of Num_major_vessels and Thallium_test for Condition.\n",
        "\n",
        "    Parameters:\n",
        "    - data: pandas DataFrame containing heart disease data.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(18, 6))\n",
        "\n",
        "    # Num_major_vessels\n",
        "    plt.subplot(1, 2, 1)\n",
        "    data['Num_major_vessels'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Num_major_vessels', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Number of major vessels colored by flourosopy for Condition')\n",
        "\n",
        "    # ST_slope\n",
        "    plt.subplot(1, 2, 2)\n",
        "    data['Thallium_test'].groupby(data['Condition']).value_counts(normalize=True).rename('proportion').reset_index().pipe((sns.barplot, 'data'), x='Thallium_test', y='proportion', hue='Condition', palette='Dark2')\n",
        "    plt.title('Thallium scintigraphy for Condition')\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [26]\n",
        "def age_distribution(data):\n",
        "    \"\"\"\n",
        "    Visualize the age distribution and its relationship with sex and condition.\n",
        "\n",
        "    Parameters:\n",
        "    - data: pandas DataFrame containing age, sex, and condition information.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(15, 7))\n",
        "\n",
        "    # Age distribution\n",
        "    plt.subplot(2, 3, 1)\n",
        "    sns.distplot(data['Age'])\n",
        "    plt.title('Age Distribution', fontsize=15)\n",
        "\n",
        "    plt.subplot(2, 3, 4)\n",
        "    sns.boxplot(data['Age'], orient='h')\n",
        "\n",
        "\n",
        "    # Age distribution for sex\n",
        "    plt.subplot(2, 3, 2)\n",
        "    female = data[data['Sex']==0]['Age']\n",
        "    male = data[data['Sex']==1]['Age']\n",
        "    sns.distplot(male, color='Blue', label='Male')\n",
        "    sns.distplot(female, color='Red', label='Female')\n",
        "    plt.title('Age Distribution (Male vs. Female)', fontsize=15)\n",
        "    plt.legend(title='Sex', fontsize=10)\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    sns.boxplot(x=data['Age'], y=data['Sex'], orient='h', palette='Set1')\n",
        "\n",
        "\n",
        "    # Age distribution for Condition\n",
        "    plt.subplot(2, 3, 3)\n",
        "    benign = data[data['Condition']==0]['Age']\n",
        "    malignant = data[data['Condition']==1]['Age']\n",
        "\n",
        "    sns.distplot(benign, color='Green', label='Benign')\n",
        "    sns.distplot(malignant, color='Red', label='Malignant')\n",
        "    plt.title('Age Distribution for Condition', fontsize=15)\n",
        "    plt.legend(title='Condition', fontsize=10)\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    sns.boxplot(x=data['Age'], y=data['Sex'], orient='h', palette='Dark2')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [27]\n",
        "def numeric_features_vs_age(data):\n",
        "    \"\"\"\n",
        "    Visualize the effects of numeric features for heart disease by age.\n",
        "\n",
        "    Parameters:\n",
        "    - data: pandas DataFrame containing numeric features and condition labels.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    benign = data.Condition==0\n",
        "    malignant = data.Condition==1\n",
        "\n",
        "    age_benign = data.Age[benign]\n",
        "    age_malignant = data.Age[malignant]\n",
        "\n",
        "    b_color = 'MediumSeaGreen'\n",
        "    m_color = 'LightCoral'\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Resting blood pressure (mmHg)\n",
        "    plt.subplot(2, 2, 1)\n",
        "    plt.scatter(x=age_benign, y=data.Resting_bp[benign], color=b_color)\n",
        "    plt.scatter(x=age_malignant, y=data.Resting_bp[malignant], color=m_color)\n",
        "    plt.title('Resting_bp vs. age', fontsize=15)\n",
        "    plt.legend(['Benign', 'Malignant'])\n",
        "    plt.xlabel('age', fontsize=10)\n",
        "    plt.ylabel('Resting blood pressure (mmHg)', fontsize=10)\n",
        "\n",
        "\n",
        "    # Serum Cholesterol (mg/dl)\n",
        "    plt.subplot(2, 2, 2)\n",
        "    plt.scatter(x=age_benign, y=data.Cholesterol[benign], color=b_color)\n",
        "    plt.scatter(x=age_malignant, y=data.Cholesterol[malignant], color=m_color)\n",
        "    plt.title('Serum cholesterol (mg/dl)', fontsize=15)\n",
        "    plt.legend(['Benign', 'Malignant'])\n",
        "    plt.xlabel('age', fontsize=10)\n",
        "    plt.ylabel('chol', fontsize=10)\n",
        "\n",
        "\n",
        "    # Maximum heart rate achieved (bpm)\n",
        "    plt.subplot(2, 2, 3)\n",
        "    plt.scatter(x=age_benign, y=data.Max_heart_rate[benign], color=b_color)\n",
        "    plt.scatter(x=age_malignant, y=data.Max_heart_rate[malignant], color=m_color)\n",
        "    plt.title('Max_heart_rate vs. age', fontsize=15)\n",
        "    plt.legend(['Benign', 'Malignant'])\n",
        "    plt.xlabel('age',fontsize=10)\n",
        "    plt.ylabel('Maximum heart rate achieved (bpm)', fontsize=10)\n",
        "\n",
        "\n",
        "    # ST_depression\n",
        "    plt.subplot(2, 2, 4)\n",
        "    plt.scatter(x=age_benign, y=data.ST_depression[benign], color=b_color)\n",
        "    plt.scatter(x=age_malignant, y=data.ST_depression[malignant], color=m_color)\n",
        "    plt.title('ST_depression vs. age', fontsize=15)\n",
        "    plt.legend(['Benign', 'Malignant'])\n",
        "    plt.xlabel('age',fontsize=10)\n",
        "    plt.ylabel('ST_depression', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# [28]\n",
        "def feature_by_Condition(data):\n",
        "  \"\"\"\n",
        "  25 GRAPHS THAT PRESENTS EACH FEATURE BY CONDITION**\n",
        "\n",
        "  Generate pair plots for each feature by condition.\n",
        "\n",
        "  Parameters:\n",
        "  - data: pandas DataFrame containing features and condition labels.\n",
        "\n",
        "  Returns:\n",
        "  - None\n",
        "  \"\"\"\n",
        "  sns.pairplot(data[['Resting_bp','Cholesterol','Max_heart_rate','ST_depression','Age', 'Condition']],hue='Condition', palette='Dark2');\n",
        "\n",
        "\n",
        "\n",
        "# [29]\n",
        "def correlation_heatmap(data):\n",
        "    \"\"\"\n",
        "    Generate a correlation heatmap of the features.\n",
        "\n",
        "    Parameters:\n",
        "    - data: pandas DataFrame containing numerical features.\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(11, 7))\n",
        "    sns.heatmap(data.corr(), annot=True, linewidth=0.2,\n",
        "                fmt='.2f', cmap='RdGy_r')\n",
        "    plt.title('Correlations between Features', fontsize=15)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Normalising the data which ensures the ML algorithims converge faster\n",
        "def get_normalisation(train_data, test_data=None):\n",
        "    \"\"\"Normalize the data using MinMaxScaler.\n",
        "\n",
        "    Parameters:\n",
        "    - train_data: Training data to fit the scaler.\n",
        "    - test_data: Optional test data to transform using the same scaler.\n",
        "\n",
        "    Returns:\n",
        "    - train_data_normalized: Normalized training data.\n",
        "    - test_data_normalized: Normalized test data if provided, None otherwise.\n",
        "    \"\"\"\n",
        "\n",
        "    scaler = MinMaxScaler() # MinMaxScaler & RobustScaler achieved the highest accuracy of all 3 types of normalisation functions\n",
        "    # scaler = StandardScaler()\n",
        "    # scaler = RobustScaler()\n",
        "    train_data_normalized = scaler.fit_transform(train_data)\n",
        "\n",
        "    if test_data is not None:\n",
        "        # Transform test data using the same scaler fitted on training data\n",
        "        test_data_normalized = scaler.transform(test_data)\n",
        "    else:\n",
        "        test_data_normalized = None\n",
        "\n",
        "    return train_data_normalized, test_data_normalized\n",
        "\n",
        "\n",
        "\n",
        "# Building svm model\n",
        "def support_vector_machine(iv_train, iv_test, dv_train, dv_test):\n",
        "  \"\"\"\n",
        "  Build, fit, and evaluate Support Vector Classification model.\n",
        "\n",
        "  Parameters:\n",
        "  - iv_train: independent variables (features) of the training data\n",
        "  - iv_test: independent variables (features) of the test data\n",
        "  - dv_train: dependent variable (target) of the training data\n",
        "  - dv_test: dependent variable (target) of the test data\n",
        "  \"\"\"\n",
        "\n",
        "  # Build and fit Support Vector Classification model\n",
        "  svm_model = SVC()\n",
        "  svm_model = svm_model.fit(iv_train, dv_train)\n",
        "\n",
        "  # Evaluate model accuracy on the test data\n",
        "  svm_accuracy = get_model_accuracy(svm_model, iv_test, dv_test)\n",
        "  print(f'SVM Accuracy: {svm_accuracy:.4}')\n",
        "\n",
        "  #Predict class for iv_test -> not sure what this means\n",
        "  dv_prediction_svm = svm_model.predict(iv_test)\n",
        "\n",
        "  # Display classification report\n",
        "  print(\"Classification Report for SVM:\")\n",
        "  print(classification_report(dv_prediction_svm, dv_test))\n",
        "\n",
        "  # Return the trained SVM model\n",
        "  return svm_model\n",
        "\n",
        "\n",
        "\n",
        "#Required for gridsearch:\n",
        "def get_best_parameters_GridSearchCV(model, params, X_train, y_train):\n",
        "    \"\"\"\n",
        "    Perform grid search to find the best hyperparameters for the given model.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Machine learning model to be optimized.\n",
        "    - params: Dictionary of hyperparameters to search over.\n",
        "    - X_train: Independent variables (features) of the training data.\n",
        "    - y_train: Dependent variable (target) of the training data.\n",
        "\n",
        "    Returns:\n",
        "    - best_estimator: Best estimator found by grid search.\n",
        "    \"\"\"\n",
        "    # Perform grid search using cross-validation\n",
        "    grid_search = GridSearchCV(model, params, cv=5)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    # Get best parameters and estimator\n",
        "    best_params = grid_search.best_params_\n",
        "    best_estimator = grid_search.best_estimator_\n",
        "\n",
        "    # Print best parameters\n",
        "    print(f'Best Parameters for {type(model).__name__}: {best_params}\\n')\n",
        "\n",
        "    return best_estimator\n",
        "\n",
        "\n",
        "\n",
        "#Implementing the SVM Gridsearch method\n",
        "def SVM_gridsearch(X_train, X_test, y_train, y_test):\n",
        "  \"\"\"\n",
        "  Perform grid search to find the best hyperparameters for Support Vector Machine.\n",
        "\n",
        "  Parameters:\n",
        "  - X_train: independent variables (features) of the training data\n",
        "  - X_test: independent variables (features) of the test data\n",
        "  - y_train: dependent variable (target) of the training data\n",
        "  - y_test: dependent variable (target) of the test data\n",
        "\n",
        "  Returns:\n",
        "  - best_model: the best SVM model found by grid search\n",
        "  \"\"\"\n",
        "\n",
        "  params_svm = {'C': [0.1, 1, 10, 100],\n",
        "                'gamma': [1, 0.1, 0.01, 0.001, 'scale', 'auto'],\n",
        "                'kernel': ['linear', 'poly', 'sigmoid']}\n",
        "\n",
        "  # Initialize the SVM classifier\n",
        "  svm_model = SVC()\n",
        "\n",
        "  # Find the best hyperparameters using grid search\n",
        "  best_estimator = get_best_parameters_GridSearchCV(svm_model, params_svm, X_train, y_train)\n",
        "\n",
        "  # Train the best model on the training data\n",
        "  best_estimator.fit(X_train, y_train)\n",
        "\n",
        "  # Evaluate accuracy on the test data\n",
        "  svm_accuracy = get_model_accuracy(best_estimator, X_test, y_test)\n",
        "  print(f'SVM with GridSearchCV Accuracy: {svm_accuracy:.4}')\n",
        "\n",
        "  # Predict class for test data\n",
        "  y_pred_svm = best_estimator.predict(X_test)\n",
        "\n",
        "  # Display classification report\n",
        "  print(\"Classification Report for SVM with GridSearchCV:\")\n",
        "  print(classification_report(y_pred_svm, y_test))\n",
        "\n",
        "  return best_estimator\n",
        "\n",
        "\n",
        "\n",
        "#Implementing Logistic Regression:\n",
        "def logistic_regression(X_train, X_test, y_train, y_test):\n",
        "  \"\"\"\n",
        "  Build, fit, and evaluate Logistic Regression model.\n",
        "\n",
        "  Parameters:\n",
        "  - X_train: independent variables (features) of the training data\n",
        "  - X_test: independent variables (features) of the test data\n",
        "  - y_train: dependent variable (target) of the training data\n",
        "  - y_test: dependent variable (target) of the test data\n",
        "\n",
        "  Returns:\n",
        "  - logreg: trained Logistic Regression model\n",
        "  \"\"\"\n",
        "\n",
        "  # Build and fit Logistic Regression model\n",
        "  logreg = LogisticRegression()\n",
        "  logreg = logreg.fit(X_train, y_train)\n",
        "\n",
        "  # Accuracy in Logistic Regression model\n",
        "  logreg_acc = get_model_accuracy(logreg, X_test, y_test)\n",
        "  print(f'Logistic Regression Accuracy: {logreg_acc:.4}')\n",
        "  print()\n",
        "\n",
        "  # Predict class for X_test\n",
        "  y_pred_logreg = logreg.predict(X_test)\n",
        "\n",
        "  # Classification Report of logistic regression model\n",
        "  print(classification_report(y_pred_logreg, y_test))\n",
        "\n",
        "  return logreg\n",
        "\n",
        "\n",
        "\n",
        "#Implementing Logistic Regression WITH Gridsearch\n",
        "def logistic_regression_gridsearch(X_train, X_test, y_train, y_test):\n",
        "    \"\"\"\n",
        "    Build, fit, and evaluate Logistic Regression model with grid search.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: independent variables (features) of the training data\n",
        "    - X_test: independent variables (features) of the test data\n",
        "    - y_train: dependent variable (target) of the training data\n",
        "    - y_test: dependent variable (target) of the test data\n",
        "\n",
        "    Returns:\n",
        "    - best_model: the best logistic regression model found by grid search\n",
        "    \"\"\"\n",
        "\n",
        "    # Define grid of hyperparameters for logistic regression\n",
        "    param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "                  'penalty': ['l2'],}\n",
        "                  # 'max_iter': [100, 500, 1000],\n",
        "                  # 'class_weight': [None, 'balanced'],\n",
        "                  # }\n",
        "                  # Tested variables above for better accuracy - it had no affect.\n",
        "\n",
        "    # Initialize the Logistic Regression classifier\n",
        "    logreg = LogisticRegression()\n",
        "\n",
        "    # Perform grid search using cross-validation\n",
        "    best_estimator = get_best_parameters_GridSearchCV(logreg, param_grid, X_train, y_train)\n",
        "\n",
        "    # Train the best model on the training data\n",
        "    best_estimator.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate accuracy on the test data\n",
        "    logreg_accuracy = get_model_accuracy(best_estimator, X_test, y_test)\n",
        "    print(f'Logistic Regression Accuracy with GridSearch: {logreg_accuracy:.4f}')\n",
        "\n",
        "    # Predict class for test data\n",
        "    y_pred_logreg = best_estimator.predict(X_test)\n",
        "\n",
        "    # Display classification report\n",
        "    print(\"Classification Report for Logistic Regression:\")\n",
        "    print(classification_report(y_pred_logreg, y_test))\n",
        "\n",
        "\n",
        "\n",
        "def get_model_accuracy(model, iv_test, dv_test):\n",
        "    \"\"\"\n",
        "    Return the mean accuracy of the model on iv_test and dv_test.\n",
        "\n",
        "    Parameters:\n",
        "    - model: Trained machine learning model\n",
        "    - iv_test: Independent variables (features) of the test data\n",
        "    - dv_test: Dependent variable (target) of the test data\n",
        "\n",
        "    Returns:\n",
        "    - model_acc: Mean accuracy of the model on the test data\n",
        "    \"\"\"\n",
        "    model_acc = model.score(iv_test, dv_test)\n",
        "    return model_acc\n",
        "\n",
        "\n",
        "\n",
        "#Implementing k nearest neighbours\n",
        "def k_nearest_neighbours(X_train, X_test, y_train, y_test, n_neighbors=5):\n",
        "    \"\"\"\n",
        "    Train a KNN classifier using the provided training data and evaluate its performance on the test data.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Training features\n",
        "    - X_test: Test features\n",
        "    - y_train: Training labels\n",
        "    - y_test: Test labels\n",
        "    - n_neighbors: Number of neighbors for the KNN classifier (default=5)\n",
        "\n",
        "    Returns:\n",
        "    - accuracy: Accuracy of the trained model on the test data\n",
        "    - classification_report: Classification report showing precision, recall, and F1-score\n",
        "    \"\"\"\n",
        "    # Step 2: Create an instance of the KNeighborsClassifier class\n",
        "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
        "\n",
        "    # Step 3: Train the KNN model using the training data\n",
        "    knn.fit(X_train, y_train)\n",
        "\n",
        "    # Step 4: Make predictions on the test data\n",
        "    y_pred = knn.predict(X_test)\n",
        "\n",
        "    # Step 5: Evaluate the performance of the model\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    # print(\"Accuracy: \", accuracy)\n",
        "    print(f'KNN - Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    print(\"Classification Report for K-Nearest-Neighbours:\")\n",
        "    report = classification_report(y_test, y_pred)\n",
        "    print(report)\n",
        "\n",
        "    return accuracy, report\n",
        "\n",
        "\n",
        "\n",
        "#Implementing k nearest neighbours + GS\n",
        "def knn_gridsearch(X_train, X_test, y_train, y_test, params={'n_neighbors': [1, 2, 3, 4, 5, 6, 7, 9, 11]}, cv=5): #\n",
        "    \"\"\"Perform grid search to find the best hyperparameters for KNN.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Training features\n",
        "    - X_test: Test features\n",
        "    - y_train: Training labels\n",
        "    - y_test: Test labels\n",
        "    - params: Dictionary of hyperparameters for grid search (default={'n_neighbors': [3, 5, 7]})\n",
        "    - cv: Number of folds for cross-validation (default=5)\n",
        "\n",
        "    Returns:\n",
        "    - best_model: The best KNN model found by grid search\n",
        "    - best_params: Best hyperparameters found by grid search\n",
        "    - accuracy: Accuracy of the best model on the test data\n",
        "    - classification_report: Classification report showing precision, recall, and F1-score\n",
        "    \"\"\"\n",
        "    # Perform grid search to find the best hyperparameters for KNN\n",
        "    best_estimator = get_best_parameters_GridSearchCV(KNeighborsClassifier(), params, X_train, y_train)\n",
        "\n",
        "    # Get model accuracy on the test data\n",
        "    accuracy = get_model_accuracy(best_estimator, X_test, y_test)\n",
        "    print(f'KNN + GS Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Get classification report\n",
        "    y_pred = best_estimator.predict(X_test)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Print the classification report\n",
        "    print(\"KNN GRIDSEARCH: Classification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    return best_estimator, params, accuracy, report\n",
        "\n",
        "\n",
        "\n",
        "# Function that provides insights into which features are most relvant for predicting the target variable\n",
        "def feature_importance_analysis(X_train, y_train, column_names):\n",
        "    \"\"\"\n",
        "    Perform feature importance analysis using a Random Forest classifier.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Training feature matrix.\n",
        "    - y_train: Target vector for training.\n",
        "    - column_names: List of feature names.\n",
        "\n",
        "    Returns:\n",
        "    - sorted_features: Names of features sorted by their importance scores.\n",
        "    - sorted_importance: Importance scores of features sorted in descending order.\n",
        "    \"\"\"\n",
        "\n",
        "    # Instantiate and train the Random Forest classifier\n",
        "    rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf_classifier.fit(X_train, y_train)\n",
        "\n",
        "    # Retrieve feature importance scores\n",
        "    feature_importance = rf_classifier.feature_importances_\n",
        "\n",
        "    # Sort features by their importance scores\n",
        "    sorted_indices = feature_importance.argsort()[::-1]\n",
        "    sorted_features = [column_names[i] for i in sorted_indices]\n",
        "    sorted_importance = feature_importance[sorted_indices]\n",
        "\n",
        "    # Visualize feature importance\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.bar(range(X_train.shape[1]), sorted_importance, align='center')\n",
        "    plt.xticks(range(X_train.shape[1]), sorted_features, rotation=90)\n",
        "    plt.xlabel('Features')\n",
        "    plt.ylabel('Feature Importance Score')\n",
        "    plt.title('Feature Importance Analysis (Random Forest)')\n",
        "    plt.show()\n",
        "\n",
        "    return sorted_features, sorted_importance\n",
        "\n",
        "\n",
        "\n",
        "# Implementing Cross Validaiton\n",
        "def compare_models(X_train, y_train):\n",
        "    \"\"\"\n",
        "    Perform cross-validation with GridSearchCV for multiple classifiers.\n",
        "\n",
        "    Parameters:\n",
        "    - X_train: Training feature matrix.\n",
        "    - y_train: Target vector for training.\n",
        "\n",
        "    Returns:\n",
        "    - results: Dictionary containing the mean cross-validation scores for each classifier.\n",
        "    \"\"\"\n",
        "\n",
        "    #-param_grids: Dictionary containing parameter grids for each classifier.\n",
        "    param_grids = {\n",
        "    'SVM': {'C': [0.1, 1, 10], 'gamma': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
        "    'KNN': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'p': [1, 2]},\n",
        "    'Logistic Regression': {'C': [0.1, 1, 10], 'solver': ['liblinear', 'saga']}\n",
        "    }\n",
        "\n",
        "    # models: Dictionary containing classifiers as keys and their respective names as values.\n",
        "    models = {\n",
        "    'SVM': SVC(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000)\n",
        "    }\n",
        "\n",
        "    results = {}\n",
        "    # For each model in the dict, store accuracy in results\n",
        "    for model_name, model in models.items():\n",
        "        param_grid = param_grids[model_name]\n",
        "        clf_grid = GridSearchCV(model, param_grid, cv=5)\n",
        "        clf_grid.fit(X_train, y_train)\n",
        "        results[model_name] = clf_grid.best_score_\n",
        "\n",
        "\n",
        "    print(\"Mean cross-validation scores:\")\n",
        "    for model_name, score in results.items():\n",
        "        print(f\"{model_name}: {round(score, 4) * 100}%\")\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "#Source https://www.kaggle.com/code/microvision/heart-disease-classification/notebook\n",
        "\n",
        "def train_test_split_data(data):\n",
        "  \"\"\"\n",
        "    This function randomly splits the dataset into two subsets: one for training the ML model and other for evaluating its performance\n",
        "\n",
        "    Parameters:\n",
        "    - data: DataFrame, the input dataset containing both independent and dependent variables.\n",
        "    - test_size: float, optional (default=0.2), the proportion of the dataset to include in the testing split.\n",
        "    - random_state: int, optional (default=42), controls the randomness of the data splitting.\n",
        "\n",
        "    Returns:\n",
        "    - X_train: DataFrame, training set of independent variables.\n",
        "    - X_test: DataFrame, testing set of independent variables.\n",
        "    - y_train: Series, training set of dependent variable.\n",
        "    - y_test: Series, testing set of dependent variable.\n",
        "  \"\"\"\n",
        "  heart_data_independent_variables = data.drop(['Condition'], axis=1)\n",
        "  heart_data_dependent_variable = data.Condition\n",
        "  hdiv_train, hdiv_test, hddv_train, hddv_test = train_test_split(heart_data_independent_variables, heart_data_dependent_variable, test_size = 0.225, random_state=42)\n",
        "  # To optimize the data, a test_size of 0.2 is used.\n",
        "\n",
        "  # If programmer wanted to see where training starts from/to end - this can be printed.\n",
        "  # print(f'Shape of heartdata_independentVariable_train {hdiv_train.shape}')\n",
        "  # print(f'Shape of heartdata_indpendentVariable_test {hdiv_test.shape}')\n",
        "  # print(f'Shape of heartdata_dependentVariable_train {hddv_train.shape}')\n",
        "  # print(f'Shape of heartdata_dependentVariable_test {hddv_test.shape}')\n",
        "\n",
        "  return hdiv_train, hdiv_test, hddv_train, hddv_test\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def __main__():\n",
        "  \"\"\" this function will hold the main functions required to run this file \"\"\"\n",
        "  uploaded = files.upload()                      #this is how googlCollab allows files to be uploaded\n",
        "  heart_data = readData()                        #heart_data is now the CSV file I will be querying.\n",
        "  heart_data = renameColumns(heart_data)         #renames the columns to something more readable\n",
        "  hd_indVar_train, hd_indVar_test, hd_depVar_train, hd_depVar_test = train_test_split_data(heart_data) # splitting the data #indVar = independent variable; depVar = dependent...\n",
        "  hd_indVar_train_normalised, hd_indVar_test_normalised = get_normalisation(hd_indVar_train, hd_indVar_test)  #Normalising the independent variable data:\n",
        "\n",
        "  # describeData(heart_data)                     # [6]  prints a summary of numeric statistics\n",
        "  # infoData(heart_data)                         # [7]  prints the csv schema\n",
        "  # checkMissingValues(heart_data)               # [8]  prints & checks for any missing values in any columns.\n",
        "  # conditionPieChart(heart_data)                # [9]  prints a pie chart that shows the ratio between malignant and benign patients\n",
        "  # sex_ratio(heart_data)                        # [10] prints a pie chart that shows the ratio between men and women\n",
        "  # conditionPerSex(heart_data)                  # [11] prints a bar char that shows the proportion of malginant to benign per male and female patients\n",
        "  # riskFactors_bySex(heart_data)                # [12] prints 6 distribution tables that detail the risk factors in both men and women that include max heart rate, serum cholestrol level and resting-bp\n",
        "  # risk_factors_dist_condition(heart_data)      # [13] prints histplots of risk factors distribution for condition (benign, malignant)\n",
        "  # risk_factors_dist(heart_data)                # [14] prints Show distributions of risk factors, Resting_bp, Chlesterol, and Max_heart_rate\n",
        "  # risk_factors_fbs(heart_data)                 # [15] prints Plot bar charts of fasting blood sugar (over 120 mg/dl) and compare for Sex and Condition\n",
        "  # printHead(heart_data)                        # [15] prints first 5 rows for each column in the csv file\n",
        "  # symptoms_features(heart_data)                # [16] prints two bar charts that depict the chest pain types and exercise induced angina\n",
        "  # symptoms_features_sex(heart_data)            # [17] prints Plot bar charts of chest pain type and exercise induced angina by Sex.\n",
        "  # symptoms_features_condition(heart_data)      # [18] prints Plot bar charts of chest pain type and exercise induced angina by Condition\n",
        "  # heart_functions(heart_data)                  # [19] prints a bar chart of Resting_ecg and ST_slope\n",
        "  # heart_functions_sex(heart_data)              # [20] Prints two bar charts: lot the proportion of Resting_exc and ST_slope for Sex.\n",
        "  # plot_condition_features(heart_data)          # [21] Plot the proportion of Resting_exc and ST_slope for Condition.\n",
        "  # explore_sex_related_variables(heart_data)    # [22] Make a standard distribution of ST_depression and distributions for Sex and Condition.\n",
        "  # explore_numeric_variables(heart_data)        # [23] Prints two bar graphs that plot number of vessels coloured by flourosophy and thaillium scintigraphy\n",
        "  # plot_heart_sex_proportions(heart_data)       # [24] Plot proportions of Num_major_vessels and Thallium_test for Sex.\n",
        "  # plot_heart_condition_proportions(heart_data) # [25] Plot proportions of Num_major_vessels and Thallium_test for Condition.\n",
        "  # age_distribution(heart_data)                 # [26] Makes a standard distribution and distributions for Sex\n",
        "  # numeric_features_vs_age(heart_data)          # [27] 4x Scatter graphs that show the Effects of features for heart disease by age\n",
        "  # feature_by_Condition(heart_data)             # [28] 25x Plot graphs that present features by condition\n",
        "  # correlation_heatmap(heart_data)              # [29] HEAT MAP: Correlation Heat Map of the features.\n",
        "  # feature_importance_analysis(hd_indVar_train_normalised, hd_depVar_train, heart_data.columns) #Plots a bar chart of the most important features\n",
        "  # compare_models(hd_indVar_train_normalised, hd_depVar_train)            # Calling the cross validation function\n",
        "\n",
        "  #Calling the SVM and passing in the normalised independentVariable Q's\n",
        "  # svm_model = support_vector_machine(hd_indVar_train_normalised, hd_indVar_test_normalised, hd_depVar_train, hd_depVar_test)  #Prints the accuracy of SVM along with scores of each data in a 6x5 column-rows.\n",
        "\n",
        "  #Calling the SVM model WITH gridsearch\n",
        "  svm_gridsearch = SVM_gridsearch(hd_indVar_train_normalised, hd_indVar_test_normalised, hd_depVar_train, hd_depVar_test)\n",
        "\n",
        "  #Calling the Logistic regression model\n",
        "  # logreg_model = logistic_regression(hd_indVar_train_normalised, hd_indVar_test_normalised, hd_depVar_train, hd_depVar_test)\n",
        "\n",
        "  #Calling the Logistic regression model WITH gridsearch\n",
        "  # logreg_gridsearch = logistic_regression_gridsearch(hd_indVar_train_normalised, hd_indVar_test_normalised, hd_depVar_train, hd_depVar_test) # ***** Code runs but error/weird output is shown, alongside the accuracy of the search *******\n",
        "\n",
        "  #Calling the K nearest neighbours model\n",
        "  # KNN_model = k_nearest_neighbours(hd_indVar_train_normalised, hd_indVar_test_normalised, hd_depVar_train, hd_depVar_test)\n",
        "\n",
        "  #Calling the KNN model with Gridsearch\n",
        "  # KNN_gridSearch = knn_gridsearch(hd_indVar_train_normalised, hd_indVar_test_normalised, hd_depVar_train, hd_depVar_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  __main__()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs5RGLz69eGTvAP1yIDOwW",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}